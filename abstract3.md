
### Comparison of Item Misclassification with Naive Bayesian and k-Nearest Neighbors Classifiers 

Sabrina Pereira and Ashley Swanson

There are a wide variety of methods and computational tools available for purposes of classification. To ensure that the correct tool is picked for the problem, it is important to know - does choosing a specific classifier over another matter, and if so, will there be differences in the items that they misclassify? To explore this question, we look at the differences between the classification outcomes of a k-nearest neighbors (k-NN) and a naive Bayesian classifier trained on the same Iris dataset to 95% accuracy. We find that of the 5% misclassified, the classifiers differed in the breakdown of of misclassified iris types (naive Bayesian: 46.6% versicolor to 53.4% virginica; k-NN: 34.2% versicolor to 65.8% virginica). Learning this information about classifier misclassification for a particular problem may be the key in constructing a classifier to best fit your needs. 
[Read more](https://github.com/ASHSWAN1999/Bayes-vs-Machine-Learning-Comparison)
